{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edf8a50a",
   "metadata": {},
   "source": [
    "# Building Generative AI Applications with Gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4001b6",
   "metadata": {},
   "source": [
    "## import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65dd78cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T13:23:28.912010Z",
     "start_time": "2023-08-05T13:23:25.920379Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import IPython.display\n",
    "from PIL import Image\n",
    "import base64\n",
    "from transformers import pipeline\n",
    "import gradio as gr\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #, message=\".*`max_length` will default to 20.*\")\n",
    "\n",
    "# Se voc√™ tamb√©m quiser ignorar outros avisos, pode adicionar mais linhas como esta:\n",
    "# warnings.filterwarnings(\"ignore\", message=\".*mensagem de aviso a ser ignorada.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1ba40f",
   "metadata": {},
   "source": [
    "# Image Captioning app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d66d4932",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T13:23:33.944271Z",
     "start_time": "2023-08-05T13:23:28.912974Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to ydshieh/vit-gpt2-coco-en and revision 65636df (https://huggingface.co/ydshieh/vit-gpt2-coco-en).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "task = \"image-to-text\"\n",
    "model = \"Salesforce/blip-image-captioning-base\"\n",
    "image_captioner = pipeline(\"image-to-text\") #, model = \"Salesforce/blip-image-captioning-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "efcc36c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T13:41:48.933286Z",
     "start_time": "2023-08-05T13:41:48.021824Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"chopper.webp\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'a painting of a bear with a cartoon character on it '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_url = \"chopper.webp\"\n",
    "#img_url = \"luffy.webp\"\n",
    "display(IPython.display.Image(url=img_url))\n",
    "image_captioner(img_url)[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e251f2b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T13:23:35.231293Z",
     "start_time": "2023-08-05T13:23:35.115965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def captioner(image):\n",
    "    result = image_captioner(image)\n",
    "    return result[0]['generated_text']\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=captioner,\n",
    "                    inputs=[gr.Image(label=\"Upload image\", type=\"pil\")],\n",
    "                    outputs=[gr.Textbox(label=\"Caption\")],\n",
    "                    title=\"Image Captioning with BLIP\",\n",
    "                    description=\"Caption any image using the BLIP model\",\n",
    "                    allow_flagging=\"never\",\n",
    "                    #examples=[\"christmas_dog.jpeg\", \"bird_flight.jpeg\", \"cow.jpeg\"]\n",
    "                   )\n",
    "\n",
    "demo.launch() #share=True) #, server_port=int(os.environ['PORT1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec1bdf0",
   "metadata": {},
   "source": [
    "# Text Summarization app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ced26369",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T13:23:38.645587Z",
     "start_time": "2023-08-05T13:23:35.233568Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "get_completion = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
    "\n",
    "def summarize(input):\n",
    "    output = get_completion(input)\n",
    "    return output[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd87b491",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T13:23:43.445981Z",
     "start_time": "2023-08-05T13:23:38.646481Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building . It is the tallest structure in Paris and the second tallest free-standing structure in France after the Millau Viaduct . It was the first structure in the world to reach a height of 300 metres .'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ('''The tower is 324 metres (1,063 ft) tall, about the same height\n",
    "        as an 81-storey building, and the tallest structure in Paris. \n",
    "        Its base is square, measuring 125 metres (410 ft) on each side. \n",
    "        During its construction, the Eiffel Tower surpassed the Washington \n",
    "        Monument to become the tallest man-made structure in the world,\n",
    "        a title it held for 41 years until the Chrysler Building\n",
    "        in New York City was finished in 1930. It was the first structure \n",
    "        to reach a height of 300 metres. Due to the addition of a broadcasting \n",
    "        aerial at the top of the tower in 1957, it is now taller than the \n",
    "        Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the \n",
    "        Eiffel Tower is the second tallest free-standing structure in France \n",
    "        after the Millau Viaduct.''')\n",
    "\n",
    "summarize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2a975fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T13:23:43.738718Z",
     "start_time": "2023-08-05T13:23:43.446944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# def summarize(input):\n",
    "#     output = get_completion(input)\n",
    "#     return output[0]['summary_text']\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=summarize, \n",
    "                    inputs=[gr.Textbox(label=\"Text to summarize\", lines=6)],\n",
    "                    outputs=[gr.Textbox(label=\"Result\", lines=3)],\n",
    "                    title=\"Text summarization with distilbart-cnn\",\n",
    "                    description=\"Summarize any text using the `shleifer/distilbart-cnn-12-6` model under the hood!\"\n",
    "                   )\n",
    "demo.launch() #share=True, server_port=int(os.environ['PORT2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a23479e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T13:23:43.920312Z",
     "start_time": "2023-08-05T13:23:43.740588Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c11569",
   "metadata": {},
   "source": [
    "# Named Entity Recognition app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5967fae9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T13:23:44.955956Z",
     "start_time": "2023-08-05T13:23:43.923033Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "get_completion = pipeline(\"ner\", model=\"dslim/bert-base-NER\")\n",
    "\n",
    "def ner(input):\n",
    "    output = get_completion(input)\n",
    "    return {\"text\": input, \"entities\": output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "252a6187",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T13:23:45.021592Z",
     "start_time": "2023-08-05T13:23:44.958709Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'My name is Poli and work at HuggingFace',\n",
       " 'entities': [{'entity': 'B-PER',\n",
       "   'score': 0.9872257,\n",
       "   'index': 4,\n",
       "   'word': 'Pol',\n",
       "   'start': 11,\n",
       "   'end': 14},\n",
       "  {'entity': 'B-PER',\n",
       "   'score': 0.44197148,\n",
       "   'index': 5,\n",
       "   'word': '##i',\n",
       "   'start': 14,\n",
       "   'end': 15},\n",
       "  {'entity': 'B-ORG',\n",
       "   'score': 0.9405219,\n",
       "   'index': 9,\n",
       "   'word': 'Hu',\n",
       "   'start': 28,\n",
       "   'end': 30},\n",
       "  {'entity': 'I-ORG',\n",
       "   'score': 0.8267373,\n",
       "   'index': 10,\n",
       "   'word': '##gging',\n",
       "   'start': 30,\n",
       "   'end': 35},\n",
       "  {'entity': 'I-ORG',\n",
       "   'score': 0.9957853,\n",
       "   'index': 11,\n",
       "   'word': '##F',\n",
       "   'start': 35,\n",
       "   'end': 36},\n",
       "  {'entity': 'I-ORG',\n",
       "   'score': 0.9153054,\n",
       "   'index': 12,\n",
       "   'word': '##ace',\n",
       "   'start': 36,\n",
       "   'end': 39}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner(\"My name is Poli and work at HuggingFace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "790f86ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T13:23:45.169676Z",
     "start_time": "2023-08-05T13:23:45.022611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.close_all()\n",
    "demo = gr.Interface(fn=ner,\n",
    "                    inputs=[gr.Textbox(label=\"Text to find entities\", lines=2)],\n",
    "                    outputs=[gr.HighlightedText(label=\"Text with entities\")],\n",
    "                    title=\"NER with dslim/bert-base-NER\",\n",
    "                    description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n",
    "                    allow_flagging=\"never\",\n",
    "                    #Here we introduce a new tag, examples, easy to use examples for your application\n",
    "                    examples=[\"My name is Andrew and I live in California\", \"My name is Poli and work at HuggingFace\"])\n",
    "demo.launch() #share=True, server_port=int(os.environ['PORT3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf69504f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T13:23:45.362015Z",
     "start_time": "2023-08-05T13:23:45.170585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c57e2be0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T13:23:45.418466Z",
     "start_time": "2023-08-05T13:23:45.364530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge_tokens(tokens):\n",
    "    '''\n",
    "    WHAT: Faz um loop entre os tokens para concatenar os tokens \n",
    "    com entidades I-* (intermediate token) aos B-* (begining token). \n",
    "    \n",
    "    '''\n",
    "    merged_tokens = []\n",
    "    for token in tokens:\n",
    "        if merged_tokens and token['entity'].startswith('I-') and merged_tokens[-1]['entity'].endswith(token['entity'][2:]):\n",
    "            # Se a lista merged_tokens n√£o estiver vazia.\n",
    "            # o token atual for um token intermedi√°rio (come√ßa com 'I-').\n",
    "            # a entidade do √∫ltimo token processado terminar com a mesma entidade do token atual, excluindo o prefixo 'I-'.\n",
    "            \n",
    "            last_token = merged_tokens[-1]\n",
    "            last_token['word'] += token['word'].replace('##', '')\n",
    "            last_token['end'] = token['end']\n",
    "            last_token['score'] = (last_token['score'] + token['score']) / 2\n",
    "        else:            \n",
    "            merged_tokens.append(token)\n",
    "\n",
    "    return merged_tokens\n",
    "\n",
    "def ner(input):\n",
    "    \"\"\"\n",
    "    WHAT: Aplica a task de NER com o hugginface pipeline e concatena os tokens com a mesma entidade.\n",
    "    RETURN: retorna um dicion√°rio com o token e suas entidades.\n",
    "    \"\"\"\n",
    "    output = get_completion(input) \n",
    "    merged_tokens = merge_tokens(output)\n",
    "    return {\"text\": input, \"entities\": merged_tokens}\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=ner,\n",
    "                    inputs=[gr.Textbox(label=\"Text to find entities\", lines=2)],\n",
    "                    outputs=[gr.HighlightedText(label=\"Text with entities\")],\n",
    "                    title=\"NER with dslim/bert-base-NER\",\n",
    "                    description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n",
    "                    allow_flagging=\"never\",\n",
    "                    examples=[\"My name is Andrew, I'm building DeeplearningAI and I live in California\", \"My name is Poli, I live in Vienna and work at HuggingFace\"])\n",
    "\n",
    "demo.launch() #share=True, server_port=int(os.environ['PORT4']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e51dee5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T13:23:45.610818Z",
     "start_time": "2023-08-05T13:23:45.419530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7917b3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Image Generation App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79b0c9a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T13:38:57.138541Z",
     "start_time": "2023-08-05T13:38:57.134866Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from diffusers import DiffusionPipeline\n",
    "\n",
    "# pipeline = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n",
    "\n",
    "# def get_completion(prompt):\n",
    "#     return pipeline(prompt).images[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe345ca4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T13:23:45.625353Z",
     "start_time": "2023-08-05T13:23:45.620485Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# prompt = \"a dog in a park\"\n",
    "\n",
    "# result = get_completion(prompt)\n",
    "# IPython.display.HTML(f'<img src=\"data:image/png;base64,{result}\" />')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78b5c1f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T13:23:45.631935Z",
     "start_time": "2023-08-05T13:23:45.628181Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import gradio as gr \n",
    "\n",
    "# #A helper function to convert the PIL image to base64\n",
    "# #so you can send it to the API\n",
    "# def base64_to_pil(img_base64):\n",
    "#     base64_decoded = base64.b64decode(img_base64)\n",
    "#     byte_stream = io.BytesIO(base64_decoded)\n",
    "#     pil_image = Image.open(byte_stream)\n",
    "#     return pil_image\n",
    "\n",
    "# def generate(prompt):\n",
    "#     output = get_completion(prompt)\n",
    "#     result_image = base64_to_pil(output)\n",
    "#     return result_image\n",
    "\n",
    "# gr.close_all()\n",
    "# demo = gr.Interface(fn=generate,\n",
    "#                     inputs=[gr.Textbox(label=\"Your prompt\")],\n",
    "#                     outputs=[gr.Image(label=\"Result\")],\n",
    "#                     title=\"Image Generation with Stable Diffusion\",\n",
    "#                     description=\"Generate any image with Stable Diffusion\",\n",
    "#                     allow_flagging=\"never\",\n",
    "#                     examples=[\"the spirit of a tamagotchi wandering in the city of Vienna\",\"a mecha robot in a favela\"])\n",
    "\n",
    "# demo.launch(share=True, server_port=int(os.environ['PORT1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5f35209",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T13:23:45.636608Z",
     "start_time": "2023-08-05T13:23:45.633879Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "caef7bba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T13:23:45.645320Z",
     "start_time": "2023-08-05T13:23:45.639291Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import gradio as gr \n",
    "\n",
    "# #A helper function to convert the PIL image to base64 \n",
    "# # so you can send it to the API\n",
    "# def base64_to_pil(img_base64):\n",
    "#     base64_decoded = base64.b64decode(img_base64)\n",
    "#     byte_stream = io.BytesIO(base64_decoded)\n",
    "#     pil_image = Image.open(byte_stream)\n",
    "#     return pil_image\n",
    "\n",
    "# def generate(prompt, negative_prompt, steps, guidance, width, height):\n",
    "#     params = {\n",
    "#         \"negative_prompt\": negative_prompt,\n",
    "#         \"num_inference_steps\": steps,\n",
    "#         \"guidance_scale\": guidance,\n",
    "#         \"width\": width,\n",
    "#         \"height\": height\n",
    "#     }\n",
    "    \n",
    "#     output = get_completion(prompt, params)\n",
    "#     pil_image = base64_to_pil(output)\n",
    "#     return pil_image\n",
    "\n",
    "# gr.close_all()\n",
    "# demo = gr.Interface(fn=generate,\n",
    "#                     inputs=[\n",
    "#                         gr.Textbox(label=\"Your prompt\"),\n",
    "#                         gr.Textbox(label=\"Negative prompt\"),\n",
    "#                         gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
    "#                                  info=\"In how many steps will the denoiser denoise the image?\"),\n",
    "#                         gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7, \n",
    "#                                   info=\"Controls how much the text prompt influences the result\"),\n",
    "#                         gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512),\n",
    "#                         gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512),\n",
    "#                     ],\n",
    "#                     outputs=[gr.Image(label=\"Result\")],\n",
    "#                     title=\"Image Generation with Stable Diffusion\",\n",
    "#                     description=\"Generate any image with Stable Diffusion\",\n",
    "#                     allow_flagging=\"never\"\n",
    "#                     )\n",
    "\n",
    "# demo.launch() #share=True, server_port=int(os.environ['PORT2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd74bf97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T13:23:45.651951Z",
     "start_time": "2023-08-05T13:23:45.647242Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fc9c12d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T13:23:45.655964Z",
     "start_time": "2023-08-05T13:23:45.653072Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# with gr.Blocks() as demo:\n",
    "#     gr.Markdown(\"# Image Generation with Stable Diffusion\")\n",
    "#     prompt = gr.Textbox(label=\"Your prompt\")\n",
    "#     with gr.Row():\n",
    "#         with gr.Column():\n",
    "#             negative_prompt = gr.Textbox(label=\"Negative prompt\")\n",
    "#             steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
    "#                       info=\"In many steps will the denoiser denoise the image?\")\n",
    "#             guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n",
    "#                       info=\"Controls how much the text prompt influences the result\")\n",
    "#             width = gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512)\n",
    "#             height = gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512)\n",
    "#             btn = gr.Button(\"Submit\")\n",
    "#         with gr.Column():\n",
    "#             output = gr.Image(label=\"Result\")\n",
    "\n",
    "#     btn.click(fn=generate, inputs=[prompt,negative_prompt,steps,guidance,width,height], outputs=[output])\n",
    "# gr.close_all()\n",
    "# demo.launch() #share=True, server_port=int(os.environ['PORT3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b155036a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T13:23:45.661260Z",
     "start_time": "2023-08-05T13:23:45.656627Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# with gr.Blocks() as demo:\n",
    "#     gr.Markdown(\"# Image Generation with Stable Diffusion\")\n",
    "#     with gr.Row():\n",
    "#         with gr.Column(scale=4):\n",
    "#             prompt = gr.Textbox(label=\"Your prompt\") #Give prompt some real estate\n",
    "#         with gr.Column(scale=1, min_width=50):\n",
    "#             btn = gr.Button(\"Submit\") #Submit button side by side!\n",
    "#     with gr.Accordion(\"Advanced options\", open=False): #Let's hide the advanced options!\n",
    "#             negative_prompt = gr.Textbox(label=\"Negative prompt\")\n",
    "#             with gr.Row():\n",
    "#                 with gr.Column():\n",
    "#                     steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
    "#                       info=\"In many steps will the denoiser denoise the image?\")\n",
    "#                     guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n",
    "#                       info=\"Controls how much the text prompt influences the result\")\n",
    "#                 with gr.Column():\n",
    "#                     width = gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512)\n",
    "#                     height = gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512)\n",
    "#     output = gr.Image(label=\"Result\") #Move the output up too\n",
    "            \n",
    "#     btn.click(fn=generate, inputs=[prompt,negative_prompt,steps,guidance,width,height], outputs=[output])\n",
    "\n",
    "# gr.close_all()\n",
    "# demo.launch() #share=True, server_port=int(os.environ['PORT4']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42574e23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T13:23:45.666578Z",
     "start_time": "2023-08-05T13:23:45.663053Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# gr.close_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda4d24e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Describe-and-Generate game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5924cfaa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "to-do:\n",
    "coletar o output do image captioner\n",
    "colocar o output do image captioner como input do image generation app\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ef509e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #Bringing the functions from lessons 3 and 4!\n",
    "# def image_to_base64_str(pil_image):\n",
    "#     byte_arr = io.BytesIO()\n",
    "#     pil_image.save(byte_arr, format='PNG')\n",
    "#     byte_arr = byte_arr.getvalue()\n",
    "#     return str(base64.b64encode(byte_arr).decode('utf-8'))\n",
    "\n",
    "# def base64_to_pil(img_base64):\n",
    "#     base64_decoded = base64.b64decode(img_base64)\n",
    "#     byte_stream = io.BytesIO(base64_decoded)\n",
    "#     pil_image = Image.open(byte_stream)\n",
    "#     return pil_image\n",
    "\n",
    "# def captioner(image):\n",
    "#     base64_image = image_to_base64_str(image)\n",
    "#     result = get_completion(base64_image, None, ITT_ENDPOINT)\n",
    "#     return result[0]['generated_text']\n",
    "\n",
    "# def generate(prompt):\n",
    "#     output = get_completion(prompt, None, TTI_ENDPOINT)\n",
    "#     result_image = base64_to_pil(output)\n",
    "#     return result_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac977f3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import gradio as gr \n",
    "# with gr.Blocks() as demo:\n",
    "#     gr.Markdown(\"# Describe-and-Generate game üñçÔ∏è\")\n",
    "#     image_upload = gr.Image(label=\"Your first image\",type=\"pil\")\n",
    "#     btn_caption = gr.Button(\"Generate caption\")\n",
    "#     caption = gr.Textbox(label=\"Generated caption\")\n",
    "    \n",
    "#     btn_caption.click(fn=captioner, inputs=[image_upload], outputs=[caption])\n",
    "\n",
    "# gr.close_all()\n",
    "# demo.launch(share=True, server_port=int(os.environ['PORT1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edf8fcd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# with gr.Blocks() as demo:\n",
    "#     gr.Markdown(\"# Describe-and-Generate game üñçÔ∏è\")\n",
    "#     image_upload = gr.Image(label=\"Your first image\",type=\"pil\")\n",
    "#     btn_caption = gr.Button(\"Generate caption\")\n",
    "#     caption = gr.Textbox(label=\"Generated caption\")\n",
    "#     btn_image = gr.Button(\"Generate image\")\n",
    "#     image_output = gr.Image(label=\"Generated Image\")\n",
    "#     btn_caption.click(fn=captioner, inputs=[image_upload], outputs=[caption])\n",
    "#     btn_image.click(fn=generate, inputs=[caption], outputs=[image_output])\n",
    "\n",
    "# gr.close_all()\n",
    "# demo.launch(share=True, server_port=int(os.environ['PORT2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f983c2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def caption_and_generate(image):\n",
    "#     caption = captioner(image)\n",
    "#     image = generate(caption)\n",
    "#     return [caption, image]\n",
    "\n",
    "# with gr.Blocks() as demo:\n",
    "#     gr.Markdown(\"# Describe-and-Generate game üñçÔ∏è\")\n",
    "#     image_upload = gr.Image(label=\"Your first image\",type=\"pil\")\n",
    "#     btn_all = gr.Button(\"Caption and generate\")\n",
    "#     caption = gr.Textbox(label=\"Generated caption\")\n",
    "#     image_output = gr.Image(label=\"Generated Image\")\n",
    "\n",
    "#     btn_all.click(fn=caption_and_generate, inputs=[image_upload], outputs=[caption, image_output])\n",
    "\n",
    "# gr.close_all()\n",
    "# demo.launch(share=True, server_port=int(os.environ['PORT3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b9dcbb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# gr.close_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323be41d",
   "metadata": {},
   "source": [
    "# Chat App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a472fa0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-05T14:15:09.206Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f3157c30c3a43aba04b2b2c61d9771d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)l-00002-of-00002.bin:   0%|          | 0.00/4.48G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "task = \"text-generation\"\n",
    "model = \"tiiuae/falcon-7b-instruct\" # or \"tiiuae/falcon-40b-instruct\"\n",
    "get_completion = pipeline(task=task, model=model, trust_remote_code=True)\n",
    "\n",
    "# def summarize(input):\n",
    "#     output = get_completion(input)\n",
    "#     return output[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca0af98",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://huggingface.co/spaces/mikeee/falcon-7b-ggml/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba08e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### exemplo\n",
    "\n",
    "# from transformers import pipeline\n",
    "\n",
    "# # Carregar o modelo pr√©-treinado\n",
    "# generator = pipeline(model=\"text-generation\", model_card=\"gpt2\")\n",
    "\n",
    "# # Instru√ß√µes de in√≠cio do chat\n",
    "# print(\"Ol√°! Sou um assistente virtual. Pergunte-me sobre o clima ou digite 'sair' para encerrar o chat.\")\n",
    "\n",
    "# while True:\n",
    "#     # Obter a entrada do usu√°rio\n",
    "#     user_input = input(\"Voc√™: \")\n",
    "\n",
    "#     # Verificar se o usu√°rio quer sair\n",
    "#     if user_input.lower() == \"sair\":\n",
    "#         print(\"At√© logo!\")\n",
    "#         break\n",
    "\n",
    "#     # Gerar uma resposta do modelo\n",
    "#     response = generator(user_input, max_length=50, do_sample=True, temperature=0.7)[0]['generated_text']\n",
    "\n",
    "#     # Exibir a resposta do assistente virtual\n",
    "#     print(\"Assistente: \", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcc5071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import io\n",
    "# import IPython.display\n",
    "# from PIL import Image\n",
    "# import base64 \n",
    "# import requests \n",
    "# requests.adapters.DEFAULT_TIMEOUT = 60\n",
    "\n",
    "# from dotenv import load_dotenv, find_dotenv\n",
    "# _ = load_dotenv(find_dotenv()) # read local .env file\n",
    "# hf_api_key = os.environ['HF_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d471197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Helper function\n",
    "# import requests, json\n",
    "# from text_generation import Client\n",
    "\n",
    "# #FalcomLM-instruct endpoint on the text_generation library\n",
    "# client = Client(os.environ['HF_API_FALCOM_BASE'], headers={\"Authorization\": f\"Basic {hf_api_key}\"}, timeout=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d5ec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"Has math been invented or discovered?\"\n",
    "# client.generate(prompt, max_new_tokens=256).generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d41dea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Back to Lesson 2, time flies!\n",
    "# import gradio as gr\n",
    "# def generate(input, slider):\n",
    "#     output = client.generate(input, max_new_tokens=slider).generated_text\n",
    "#     return output\n",
    "\n",
    "# demo = gr.Interface(fn=generate, inputs=[gr.Textbox(label=\"Prompt\"), gr.Slider(label=\"Max new tokens\", value=20,  maximum=1024, minimum=1)], outputs=[gr.Textbox(label=\"Completion\")])\n",
    "# gr.close_all()\n",
    "# demo.launch(share=True, server_port=int(os.environ['PORT1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12565ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# def respond(message, chat_history):\n",
    "#         #No LLM here, just respond with a random pre-made message\n",
    "#         bot_message = random.choice([\"Tell me more about it\", \n",
    "#                                      \"Cool, but I'm not interested\", \n",
    "#                                      \"Hmmmm, ok then\"]) \n",
    "#         chat_history.append((message, bot_message))\n",
    "#         return \"\", chat_history\n",
    "\n",
    "# with gr.Blocks() as demo:\n",
    "#     chatbot = gr.Chatbot(height=240) #just to fit the notebook\n",
    "#     msg = gr.Textbox(label=\"Prompt\")\n",
    "#     btn = gr.Button(\"Submit\")\n",
    "#     clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "\n",
    "#     btn.click(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "#     msg.submit(respond, inputs=[msg, chatbot], outputs=[msg, chatbot]) #Press enter to submit\n",
    "# gr.close_all()\n",
    "# demo.launch(share=True, server_port=int(os.environ['PORT2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d3c45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### adicionando contexto (hist√≥rico)\n",
    "\n",
    "# def format_chat_prompt(message, chat_history):\n",
    "#     prompt = \"\"\n",
    "#     for turn in chat_history:\n",
    "#         user_message, bot_message = turn\n",
    "#         prompt = f\"{prompt}\\nUser: {user_message}\\nAssistant: {bot_message}\"\n",
    "#     prompt = f\"{prompt}\\nUser: {message}\\nAssistant:\"\n",
    "#     return prompt\n",
    "\n",
    "# def respond(message, chat_history):\n",
    "#         formatted_prompt = format_chat_prompt(message, chat_history)\n",
    "#         bot_message = client.generate(formatted_prompt,\n",
    "#                                      max_new_tokens=1024,\n",
    "#                                      stop_sequences=[\"\\nUser:\", \"<|endoftext|>\"] # retornando somente a resposta atual\n",
    "#                                      ).generated_text\n",
    "#         chat_history.append((message, bot_message))\n",
    "#         return \"\", chat_history\n",
    "\n",
    "# with gr.Blocks() as demo:\n",
    "#     chatbot = gr.Chatbot(height=240) #just to fit the notebook\n",
    "#     msg = gr.Textbox(label=\"Prompt\")\n",
    "#     btn = gr.Button(\"Submit\")\n",
    "#     clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "\n",
    "#     btn.click(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "#     msg.submit(respond, inputs=[msg, chatbot], outputs=[msg, chatbot]) #Press enter to submit\n",
    "# gr.close_all()\n",
    "# demo.launch(share=True, server_port=int(os.environ['PORT3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacf7817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def format_chat_prompt(message, chat_history, instruction):\n",
    "#     prompt = f\"System:{instruction}\"\n",
    "#     for turn in chat_history:\n",
    "#         user_message, bot_message = turn\n",
    "#         prompt = f\"{prompt}\\nUser: {user_message}\\nAssistant: {bot_message}\"\n",
    "#     prompt = f\"{prompt}\\nUser: {message}\\nAssistant:\"\n",
    "#     return prompt\n",
    "\n",
    "# def respond(message, chat_history, instruction, temperature=0.7):\n",
    "#     prompt = format_chat_prompt(message, chat_history, instruction)\n",
    "#     chat_history = chat_history + [[message, \"\"]]\n",
    "#     stream = client.generate_stream(prompt,\n",
    "#                                       max_new_tokens=1024,\n",
    "#                                       stop_sequences=[\"\\nUser:\", \"<|endoftext|>\"],\n",
    "#                                       temperature=temperature)\n",
    "#                                       #stop_sequences to not generate the user answer\n",
    "#     acc_text = \"\"\n",
    "#     #Streaming the tokens\n",
    "#     for idx, response in enumerate(stream):\n",
    "#             text_token = response.token.text\n",
    "\n",
    "#             if response.details:\n",
    "#                 return\n",
    "\n",
    "#             if idx == 0 and text_token.startswith(\" \"):\n",
    "#                 text_token = text_token[1:]\n",
    "\n",
    "#             acc_text += text_token\n",
    "#             last_turn = list(chat_history.pop(-1))\n",
    "#             last_turn[-1] += acc_text\n",
    "#             chat_history = chat_history + [last_turn]\n",
    "#             yield \"\", chat_history\n",
    "#             acc_text = \"\"\n",
    "\n",
    "# with gr.Blocks() as demo:\n",
    "#     chatbot = gr.Chatbot(height=240) #just to fit the notebook\n",
    "#     msg = gr.Textbox(label=\"Prompt\")\n",
    "#     with gr.Accordion(label=\"Advanced options\",open=False):\n",
    "#         system = gr.Textbox(label=\"System message\", lines=2, value=\"A conversation between a user and an LLM-based AI assistant. The assistant gives helpful and honest answers.\")\n",
    "#         temperature = gr.Slider(label=\"temperature\", minimum=0.1, maximum=1, value=0.7, step=0.1)\n",
    "#     btn = gr.Button(\"Submit\")\n",
    "#     clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "\n",
    "#     btn.click(respond, inputs=[msg, chatbot, system], outputs=[msg, chatbot])\n",
    "#     msg.submit(respond, inputs=[msg, chatbot, system], outputs=[msg, chatbot]) #Press enter to submit\n",
    "# gr.close_all()\n",
    "# demo.queue().launch(share=True, server_port=int(os.environ['PORT4']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc2906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gr.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72534224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
